def train_neural_network(x):
    trainData_in, trainData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/174_train.csv')
    testData_in, testData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/174_test.csv')
    trainData_in = np.reshape(trainData_in, [-1,n_chunks,chunk_size])
    testData_in = np.reshape(testData_in, [-1,n_chunks,chunk_size])
    prediction = recurrent_neural_network(x)

    # Use MSE as cost function to be minimized
    cost = tf.reduce_mean(tf.square(prediction - y))

    # AdamOptimizer produced better results than simple GradientDescentOptimizer
    optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)

    errors = []
    with tf.Session() as sess:
        sess.run(tf.initialize_all_variables())

        # Per-epoch training:
        for i in range(NUM_EPOCHS):
            sess.run(optimizer, feed_dict={x: trainData_in, y: trainData_out})
            if i % 10 == 0 :
                mse = sess.run(tf.reduce_mean(tf.square(prediction - y)), feed_dict={x: testData_in, y: testData_out})
                errors.append(mse)
            #    print(mse)

        print('Patient 174 data:')
        evaluateNetwork(sess, testData_in, testData_out, prediction)
        print('Patient 149 data:')
        testData_in, testData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/149_test.csv')
        testData_in = np.reshape(testData_in, [-1,n_chunks,chunk_size])
        evaluateNetwork(sess, testData_in, testData_out, prediction)
        print('Patient 151 data:')
        testData_in, testData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/151_test.csv')
        testData_in = np.reshape(testData_in, [-1,n_chunks,chunk_size])
        evaluateNetwork(sess, testData_in, testData_out, prediction)
        # Uncomment this to evaluate the current network on a different patient:
        #testData_in, testData_out = readData('tblADataRTCGM_Blind_Baseline_Split_output/78_test.csv')
        #evaluateNetwork(sess, testData_in, testData_out, prediciton)

        # Plot the MSE throughout training
        plt.plot(errors)
        plt.xlabel('#epochs')
        plt.ylabel('MSE')
        plt.show()
#End train_neural_network(x)

train_neural_network(x)
