{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glucose.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojakarthikeyan13/Non-Invasie-Continuous-glucose-monitoring-using-LSTM-algorithm/blob/master/glucose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnE4nvQ8KZ4T"
      },
      "source": [
        "!pip install tensorflow==1.2\n",
        "import tensorflow as tf\n",
        "#%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "#from tensorflow.python.ops import rnn, rnn_cell\n",
        "from tensorflow.contrib import rnn\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boqKY3tTOxLX"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r09OkrsIM0ee"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "path = '/content/gdrive/My Drive/Test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNR4fiB4Kffy"
      },
      "source": [
        "NUM_EPOCHS = 500\n",
        "batch_size = 128\n",
        "chunk_size = 1\n",
        "n_chunks = 7\n",
        "rnn_size = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aldsx-ZXKmBW"
      },
      "source": [
        "# readData reads data from the specified pre-processed input data file.\n",
        "# The function returns an array of input data points and an array of the\n",
        "# corresponding desired outputs.\n",
        "def readData(filePath) :\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    with open(filePath, 'r') as f:\n",
        "        for line in f:\n",
        "            values = line.split(',')\n",
        "            time1 = float(values[0])\n",
        "            time2 = float(values[1])\n",
        "            time3 = float(values[2])\n",
        "            time4 = float(values[3])\n",
        "            time5 = float(values[4])\n",
        "            time6 = float(values[5])\n",
        "            time7 = float(values[6])\n",
        "            time8 = float(values[7])\n",
        "            newPointx = [time1, time2, time3, time4, time5, time6, time7] # Input\n",
        "            newPointy = [time8] # Desired Output\n",
        "            x_data.append(newPointx)\n",
        "            y_data.append(newPointy)\n",
        "    data = [x_data, y_data]\n",
        "    return data;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kY1qJcuKsrC"
      },
      "source": [
        "# evaluateNetwork runs the trained network on the the provided network and\n",
        "# reports the following evaluation metrics:\n",
        "#   - mean squared prediction error\n",
        "#   - percentage of lows that were correctly identified\n",
        "#   - percentage of highs that were corretly identified\n",
        "#   - number of falsely reported lows\n",
        "#   - number of falsely reported highs\n",
        "#\n",
        "# These metrics are defined as follows:\n",
        "#   - MSE:\n",
        "#       -> Average of (y_desired - y_actual)^2 for each test point\n",
        "#   - Low prediction accuracy:\n",
        "#       -> 100 * (Number of correct lows) / (Number of lows)\n",
        "#       -> Lows are any blood glucose level less than 70 mg/dL\n",
        "#   - High prediction accuracy:\n",
        "#       -> 100 * (Number of correct highs) / (Number of highs)\n",
        "#       -> Highs are any blood glucose level greater than 200\n",
        "#   - Number of false lows:\n",
        "#       -> Number of false lows where (y_desired - y_actual) > 6\n",
        "#       -> Note: false alarms are not counted if the prediction error is small\n",
        "#   - Number of false highs:\n",
        "#       -> Number of false highs where (y_actual - y_desired) > 6\n",
        "#       -> Note: false alarms are not counted if the prediciton error is small\n",
        "def evaluateNetwork(session, inData, outData, prediction) :\n",
        "    # Compute mse:\n",
        "    mse = session.run(tf.reduce_mean(tf.square(prediction - y)), feed_dict={x: inData, y: outData})\n",
        "    numTestPoints = len(inData)\n",
        "    numPredictedLows = 0\n",
        "    numLows = 0\n",
        "    numFalseLows = 0\n",
        "    numPredictedHighs = 0\n",
        "    numHighs = 0\n",
        "    numFalseHighs = 0\n",
        "    for i, inputPoint in enumerate(inData) :\n",
        "        # Apply network on current point:\n",
        "        predicted = session.run(prediction, feed_dict={x: [inputPoint]})\n",
        "        desired = outData[i][0]\n",
        "\n",
        "        # Update numLows, numHighs:\n",
        "        if(desired < 70) :\n",
        "            numLows += 1\n",
        "        elif(desired > 200) :\n",
        "            numHighs += 1\n",
        "\n",
        "        # Update prediction counts:\n",
        "        if(predicted < 70) : # If predicted low\n",
        "            if(desired < 70) : # If low prediction was correct\n",
        "                numPredictedLows += 1\n",
        "            elif((desired - predicted) > 8) : # If low prediction was incorrect and error was 'large'\n",
        "                numFalseLows += 1\n",
        "        elif(predicted > 200) : # If predicted high\n",
        "            if(desired > 200) : # If high prediction was correct\n",
        "                numPredictedHighs += 1\n",
        "            elif((predicted - desired) > 8) : # If high prediction was incorrect and error was 'large'\n",
        "                numFalseHighs += 1\n",
        "\n",
        "    # Print results:\n",
        "    print('Number of test points: ', numTestPoints)\n",
        "    print('Number of lows: ', numLows)\n",
        "    print('Number of highs: ', numHighs)\n",
        "    print(\"Number of 'normal' points: \", numTestPoints - numLows - numHighs)\n",
        "    print('') # New line\n",
        "    print('MSE: ', mse)\n",
        "    print('')\n",
        "    print('Low prediction accuracy: ', 100 * numPredictedLows / numLows, '%')\n",
        "    print('Number of false lows: ', numFalseLows)\n",
        "    print('')\n",
        "    print('High prediction accuracy: ', 100 * numPredictedHighs / numHighs, '%')\n",
        "    print('Number of false highs: ', numFalseHighs)\n",
        "# End evaluateNetwork(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtgIoRl0Kx-i"
      },
      "source": [
        "x = tf.placeholder('float', [None, n_chunks, chunk_size])\n",
        "y = tf.placeholder('float')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rP1mbGnK13V"
      },
      "source": [
        "# recurrent_neural_network() defines the RNN model. The network architecture\n",
        "# used consists of a single LSTM cell followed by an output layer.\n",
        "def recurrent_neural_network(x):\n",
        "    layer = {'weights':tf.Variable(tf.random_normal([rnn_size, 1])),\n",
        "             'biases':tf.Variable(tf.random_normal([1]))}\n",
        "\n",
        "    # Reshape x to the format desired by the LSTM:\n",
        "    x = tf.transpose(x, [1,0,2])\n",
        "    x = tf.reshape(x, [-1, chunk_size])\n",
        "    ##changed x as 0 and 0 as x\n",
        "    x = tf.split(x, n_chunks, 0)\n",
        "\n",
        "    ##replaced rnn_cell as rnn\n",
        "    lstm_cell = rnn.BasicLSTMCell(rnn_size)##, state_is_tuple=True, activation=tf.nn.relu)\n",
        "    ##replaced rnn.rnn as rnn.static_rnn and\n",
        "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "    output = tf.matmul(outputs[-1], layer['weights']) + layer['biases']\n",
        "\n",
        "    return output\n",
        "\n",
        "# The RNN is trained by feeding in sequences of glucose measurements seprarated\n",
        "# by 10 minute intervals, and the desired output at a 20 minute prediction horizon."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idJj24OOK79G"
      },
      "source": [
        "def train_neural_network(x):\n",
        "    trainData_in, trainData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/174_train.csv')\n",
        "    testData_in, testData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/174_test.csv')\n",
        "    trainData_in = np.reshape(trainData_in, [-1,n_chunks,chunk_size])\n",
        "    testData_in = np.reshape(testData_in, [-1,n_chunks,chunk_size])\n",
        "    prediction = recurrent_neural_network(x)\n",
        "\n",
        "    # Use MSE as cost function to be minimized\n",
        "    cost = tf.reduce_mean(tf.square(prediction - y))\n",
        "\n",
        "    # AdamOptimizer produced better results than simple GradientDescentOptimizer\n",
        "    optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
        "\n",
        "    errors = []\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.initialize_all_variables())\n",
        "\n",
        "        # Per-epoch training:\n",
        "        for i in range(NUM_EPOCHS):\n",
        "            sess.run(optimizer, feed_dict={x: trainData_in, y: trainData_out})\n",
        "            if i % 10 == 0 :\n",
        "                mse = sess.run(tf.reduce_mean(tf.square(prediction - y)), feed_dict={x: testData_in, y: testData_out})\n",
        "                errors.append(mse)\n",
        "            #    print(mse)\n",
        "\n",
        "        print('Patient 174 data:')\n",
        "        evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
        "        print('Patient 149 data:')\n",
        "        testData_in, testData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/149_test.csv')\n",
        "        testData_in = np.reshape(testData_in, [-1,n_chunks,chunk_size])\n",
        "        evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
        "        print('Patient 151 data:')\n",
        "        testData_in, testData_out = readData(path+'tblADataRTCGM_Unblinded_ControlGroup_1_output_RNN_20/151_test.csv')\n",
        "        testData_in = np.reshape(testData_in, [-1,n_chunks,chunk_size])\n",
        "        evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
        "        # Uncomment this to evaluate the current network on a different patient:\n",
        "        #testData_in, testData_out = readData('tblADataRTCGM_Blind_Baseline_Split_output/78_test.csv')\n",
        "        #evaluateNetwork(sess, testData_in, testData_out, prediciton)\n",
        "\n",
        "        # Plot the MSE throughout training\n",
        "        plt.plot(errors)\n",
        "        plt.xlabel('#epochs')\n",
        "        plt.ylabel('MSE')\n",
        "        plt.show()\n",
        "#End train_neural_network(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hSvXpLAzSNB"
      },
      "source": [
        "train_neural_network(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}